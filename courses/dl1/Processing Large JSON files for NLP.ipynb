{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning Line-delimited JSON into separate files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to take the large JSON files and split them up into a single file per JSON Object. Luckily BigQuery will format the JSON file so that each object exits on its own line, so we can process it one line at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Where I've stored my large JSON files\n",
    "reddit_JSON_files='data/reddit/json/'\n",
    "write_new_files_here='data/reddit/all/'\n",
    "\n",
    "files = ! ls {reddit_JSON_files}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a single line of the file\n",
    "\n",
    "fileNumber = 0\n",
    "\n",
    "\n",
    "with open(reddit_JSON_files + files[0]) as f:\n",
    "    content = json.loads(f.readline())\n",
    "    newFileName = f'{fileNumber}.txt'\n",
    "    newFile = open(write_new_files_here + newFileName, 'w')\n",
    "    newFile.write(content['f0_']) # 'f0_' just happens to the be random field name BigQuery assigned because I forgot to declare one..\n",
    "    newFile.close()\n",
    "    # run this line to test your output:\n",
    "    # ! cat {write_new_files_here + newFileName} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fileNumber = 0\n",
    "\n",
    "\n",
    "with open(reddit_JSON_files + files[0]) as f:\n",
    "    for line in f:\n",
    "        content = json.loads(line)\n",
    "        newFileName = f'{fileNumber}.txt'\n",
    "        newFile = open(write_new_files_here + newFileName, 'w')\n",
    "        newFile.write(content['f0_']) # 'f0_' just happens to the be random field name BigQuery assigned because I forgot to declare one..\n",
    "        newFile.close()\n",
    "        fileNumber += 1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1359\r\n"
     ]
    }
   ],
   "source": [
    "# Counts how many files were made\n",
    "! ls {'data/reddit/all'} | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WP] You're sitting in your kitchen eating breakfast when a man in a lab coat walks in and says, \"The experiment is over. Thank you for your time.\" [response] I had poached eggs, the day the world ended.\r\n",
      "\r\n",
      "Now all I have is a blanket and vine-wrapped broken highway in front of me that seems to go on forever.\r\n",
      "\r\n",
      "(the highway, not the blanket.)\r\n",
      "\r\n",
      "But it started with poached eggs and a figure in a lab coat. It walked into my kitchen, stopped right by Amy's side, \r\n",
      "looking right at me.\r\n",
      "\r\n",
      "\"Thank you for your time, Mr. Taylor.\"\r\n"
     ]
    }
   ],
   "source": [
    "# inspect 10 lines of a file\n",
    "! head {'data/reddit/all/38.txt'} --lines=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
